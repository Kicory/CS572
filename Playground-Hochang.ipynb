{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS572 Project\n",
    "* We selected the paper: {}\n",
    "* Based on the data and model of given paper, we are planning to make an extension of LSTM that predicts {}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "import time\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "data_path_train = 'Data/Training' # add path\n",
    "data_path_test = 'Data/Testing'\n",
    "\n",
    "input_size = 8\n",
    "hidden_size = 128\n",
    "num_layers = 3\n",
    "num_epochs = 2000\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "weight_decay=0.00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if your computer is prepared to run pytorch model with CUDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # x -> batch_size, seq, input_size\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "#     def makehc_zero(self, batch_size):\n",
    "#         self.hn = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "#         self.cn = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "#         print(\"clear\")\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "#         if self.training == True:\n",
    "#             # Set initial hidden and cell states \n",
    "#             self.makehc_zero(x.size(0))\n",
    "\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "#         out, (self.hn, self.cn) = self.lstm(x, (self.hn, self.cn))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        \n",
    "        out, (self.hm, self.cn) = self.lstm(x,(h0,c0))\n",
    "\n",
    "        out_original = out\n",
    "        out_original_fc = self.fc(out_original) # out_original : Tensor of shape (batch_size, seq_length, 1)\n",
    "        \n",
    "#         pred_y = self.fc(out[-1].view(x.size(1),-1)) # pred_y : tensor of shape (40,1), taking the last section of a batch\n",
    "#         print(\"This is x.size(1):\", x.size(1))\n",
    "#         print(\"This is out[-1] :\", out[-1].shape)\n",
    "#         print(out[-1])\n",
    "#         print(\"This is out[-1].view(x.size(1),-1):\", out[-1].view(x.size(1),-1).shape)\n",
    "#         print(out[-1].view(x.size(1),-1))\n",
    "#         print(\"This is pred_y : \", pred_y.shape)\n",
    "#         print(pred_y)\n",
    "        \n",
    "\n",
    "#         out = out[:, -1, :]\n",
    "#         print(\"This is output right before linear : \", out.shape)\n",
    "#         out = self.fc(out)\n",
    "#         print(\"This is output after linear : \", out.shape)\n",
    "#         print(out)\n",
    "        \n",
    "        return out_original_fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Testing: To train fingertip forces from input\n",
    "# data, a three-layer BT-LSTM with 128 hidden units is used.\n",
    "# Sequence time length of BT-LSTM was set to T = 40. The final\n",
    "# output of the BT-LSTM layer is fed into the final fully-connected\n",
    "# layer to obtain the one-dimensional output. The mean squared\n",
    "# error (MSE) function is used to measure the loss between the\n",
    "# predicted and the ground truth contact force. During training,\n",
    "# the number of epoch was 2000, and the mini batch size was 32.\n",
    "# Adam optimizer was used with 0.001 learning rate and 10âˆ’5\n",
    "# weight decay\n",
    "lstm = LSTM(input_size, hidden_size, num_layers).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(lstm.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load cell if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.load_state_dict(torch.load('model.ckpt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/Training\\190722_tension_test_space_1_trial_2.csv\n",
      "Epoch [10/2000], Loss: 0.5635\n",
      "time : 1.1653928756713867\n",
      "Epoch [20/2000], Loss: 0.5122\n",
      "time : 2.2076048851013184\n",
      "Epoch [30/2000], Loss: 0.7140\n",
      "time : 3.245828151702881\n",
      "Epoch [40/2000], Loss: 0.5939\n",
      "time : 4.2925379276275635\n",
      "Epoch [50/2000], Loss: 0.4798\n",
      "time : 5.321784734725952\n",
      "Epoch [60/2000], Loss: 0.6846\n",
      "time : 6.365991592407227\n",
      "Epoch [70/2000], Loss: 1.6757\n",
      "time : 7.4082043170928955\n",
      "Epoch [80/2000], Loss: 0.3441\n",
      "time : 8.425988912582397\n",
      "Epoch [90/2000], Loss: 0.7402\n",
      "time : 9.461220502853394\n",
      "Epoch [100/2000], Loss: 0.6738\n",
      "time : 10.477445125579834\n",
      "training complete\n",
      "Data/Training\\190722_tension_test_space_1_trial_3.csv\n",
      "Epoch [10/2000], Loss: 2.3629\n",
      "time : 5.750633955001831\n",
      "Epoch [20/2000], Loss: 0.7375\n",
      "time : 11.424978494644165\n",
      "Epoch [30/2000], Loss: 2.6981\n",
      "time : 17.084346532821655\n",
      "Epoch [40/2000], Loss: 0.7175\n",
      "time : 22.77531099319458\n",
      "Epoch [50/2000], Loss: 0.1489\n",
      "time : 28.423710346221924\n",
      "Epoch [60/2000], Loss: 1.9131\n",
      "time : 34.050182580947876\n",
      "Epoch [70/2000], Loss: 0.8536\n",
      "time : 39.64374375343323\n",
      "Epoch [80/2000], Loss: 0.4690\n",
      "time : 45.29514765739441\n",
      "Epoch [90/2000], Loss: 0.3441\n",
      "time : 51.25672388076782\n",
      "Epoch [100/2000], Loss: 0.4993\n",
      "time : 57.09811472892761\n",
      "training complete\n",
      "Data/Training\\190722_tension_test_space_2_trial_1.csv\n",
      "Epoch [10/2000], Loss: 1.2717\n",
      "time : 1.3035142421722412\n",
      "Epoch [20/2000], Loss: 0.6877\n",
      "time : 2.5611507892608643\n",
      "Epoch [30/2000], Loss: 0.5868\n",
      "time : 3.800342082977295\n",
      "Epoch [40/2000], Loss: 0.3129\n",
      "time : 5.054987192153931\n",
      "Epoch [50/2000], Loss: 0.6062\n",
      "time : 6.309838533401489\n",
      "Epoch [60/2000], Loss: 0.7135\n",
      "time : 7.594908714294434\n",
      "Epoch [70/2000], Loss: 0.5007\n",
      "time : 8.803675413131714\n",
      "Epoch [80/2000], Loss: 0.5165\n",
      "time : 10.043866395950317\n",
      "Epoch [90/2000], Loss: 0.3040\n",
      "time : 11.268591165542603\n",
      "Epoch [100/2000], Loss: 0.4407\n",
      "time : 12.543182373046875\n",
      "training complete\n",
      "Data/Training\\190722_tension_test_space_2_trial_2.csv\n",
      "Epoch [10/2000], Loss: 0.4560\n",
      "time : 1.86696195602417\n",
      "Epoch [20/2000], Loss: 0.5986\n",
      "time : 3.698063373565674\n",
      "Epoch [30/2000], Loss: 0.8368\n",
      "time : 5.506227016448975\n",
      "Epoch [40/2000], Loss: 0.1686\n",
      "time : 7.31638503074646\n",
      "Epoch [50/2000], Loss: 0.6899\n",
      "time : 9.09562635421753\n",
      "Epoch [60/2000], Loss: 0.5414\n",
      "time : 10.883857488632202\n",
      "Epoch [70/2000], Loss: 1.1114\n",
      "time : 12.715956449508667\n",
      "Epoch [80/2000], Loss: 0.8743\n",
      "time : 14.517139196395874\n",
      "Epoch [90/2000], Loss: 0.8440\n",
      "time : 16.29637885093689\n",
      "Epoch [100/2000], Loss: 0.3932\n",
      "time : 18.06963539123535\n",
      "training complete\n",
      "Data/Training\\190722_tension_test_space_2_trial_4.csv\n",
      "Epoch [10/2000], Loss: 0.6260\n",
      "time : 4.332386493682861\n",
      "Epoch [20/2000], Loss: 1.0647\n",
      "time : 8.579763889312744\n",
      "Epoch [30/2000], Loss: 0.6298\n",
      "time : 12.837818384170532\n",
      "Epoch [40/2000], Loss: 0.7450\n",
      "time : 17.115882873535156\n",
      "Epoch [50/2000], Loss: 0.5035\n",
      "time : 21.378496885299683\n",
      "Epoch [60/2000], Loss: 0.5802\n",
      "time : 25.63811683654785\n",
      "Epoch [70/2000], Loss: 0.3259\n",
      "time : 29.90571880340576\n",
      "Epoch [80/2000], Loss: 0.6069\n",
      "time : 34.165847301483154\n",
      "Epoch [90/2000], Loss: 0.5693\n",
      "time : 38.46784710884094\n",
      "Epoch [100/2000], Loss: 0.3975\n",
      "time : 42.83268117904663\n",
      "training complete\n",
      "Data/Training\\190722_tension_test_space_3_trial_2.csv\n",
      "Epoch [10/2000], Loss: 0.7957\n",
      "time : 1.1259865760803223\n",
      "Epoch [20/2000], Loss: 0.3740\n",
      "time : 2.174182653427124\n",
      "Epoch [30/2000], Loss: 0.6438\n",
      "time : 3.2333500385284424\n",
      "Epoch [40/2000], Loss: 0.4681\n",
      "time : 4.315454959869385\n",
      "Epoch [50/2000], Loss: 0.5539\n",
      "time : 5.370632171630859\n",
      "Epoch [60/2000], Loss: 0.3521\n",
      "time : 6.433788776397705\n",
      "Epoch [70/2000], Loss: 0.3928\n",
      "time : 7.4979424476623535\n",
      "Epoch [80/2000], Loss: 0.2434\n",
      "time : 8.567082405090332\n",
      "Epoch [90/2000], Loss: 0.3085\n",
      "time : 9.637219905853271\n",
      "Epoch [100/2000], Loss: 0.4440\n",
      "time : 10.700375318527222\n",
      "training complete\n",
      "Data/Training\\190722_tension_test_space_3_trial_3.csv\n",
      "Epoch [10/2000], Loss: 2.3275\n",
      "time : 1.2406811714172363\n",
      "Epoch [20/2000], Loss: 0.7877\n",
      "time : 2.4005770683288574\n",
      "Epoch [30/2000], Loss: 1.5080\n",
      "time : 3.5465123653411865\n",
      "Epoch [40/2000], Loss: 1.2109\n",
      "time : 4.705413103103638\n",
      "Epoch [50/2000], Loss: 0.4201\n",
      "time : 5.870708703994751\n",
      "Epoch [60/2000], Loss: 1.0909\n",
      "time : 7.007177114486694\n",
      "Epoch [70/2000], Loss: 1.2678\n",
      "time : 8.134162902832031\n",
      "Epoch [80/2000], Loss: 1.8524\n",
      "time : 9.282092332839966\n",
      "Epoch [90/2000], Loss: 1.7182\n",
      "time : 10.437999725341797\n",
      "Epoch [100/2000], Loss: 0.6556\n",
      "time : 11.580454587936401\n",
      "training complete\n",
      "Data/Training\\190722_tension_test_space_3_trial_4.csv\n",
      "Epoch [10/2000], Loss: 2.1070\n",
      "time : 1.8500518798828125\n",
      "Epoch [20/2000], Loss: 1.6048\n",
      "time : 3.635174512863159\n",
      "Epoch [30/2000], Loss: 0.2921\n",
      "time : 5.460293292999268\n",
      "Epoch [40/2000], Loss: 0.3341\n",
      "time : 7.259479999542236\n",
      "Epoch [50/2000], Loss: 0.9736\n",
      "time : 9.047205686569214\n",
      "Epoch [60/2000], Loss: 0.3494\n",
      "time : 10.833428382873535\n",
      "Epoch [70/2000], Loss: 0.4648\n",
      "time : 12.650585174560547\n",
      "Epoch [80/2000], Loss: 0.5279\n",
      "time : 14.448773384094238\n",
      "Epoch [90/2000], Loss: 1.9031\n",
      "time : 16.2644681930542\n",
      "Epoch [100/2000], Loss: 1.9673\n",
      "time : 18.053191423416138\n",
      "training complete\n",
      "Data/Training\\190722_tension_test_space_3_trial_5.csv\n",
      "Epoch [10/2000], Loss: 2.4230\n",
      "time : 1.6645464897155762\n",
      "Epoch [20/2000], Loss: 1.5324\n",
      "time : 3.295691728591919\n",
      "Epoch [30/2000], Loss: 1.4874\n",
      "time : 4.9412901401519775\n",
      "Epoch [40/2000], Loss: 2.3998\n",
      "time : 6.578909397125244\n",
      "Epoch [50/2000], Loss: 2.5579\n",
      "time : 8.223534345626831\n",
      "Epoch [60/2000], Loss: 4.3240\n",
      "time : 9.820263862609863\n",
      "Epoch [70/2000], Loss: 2.2479\n",
      "time : 11.447418451309204\n",
      "Epoch [80/2000], Loss: 2.1921\n",
      "time : 13.054627180099487\n",
      "Epoch [90/2000], Loss: 0.9677\n",
      "time : 14.707206726074219\n",
      "Epoch [100/2000], Loss: 0.6210\n",
      "time : 16.324388027191162\n",
      "training complete\n",
      "Data/Training\\190722_tension_test_space_3_trial_6.csv\n",
      "Epoch [10/2000], Loss: 1.1851\n",
      "time : 1.7781412601470947\n",
      "Epoch [20/2000], Loss: 0.5421\n",
      "time : 3.5015299320220947\n",
      "Epoch [30/2000], Loss: 0.1546\n",
      "time : 5.224937677383423\n",
      "Epoch [40/2000], Loss: 0.8161\n",
      "time : 6.940349578857422\n",
      "Epoch [50/2000], Loss: 0.3247\n",
      "time : 8.642794847488403\n",
      "Epoch [60/2000], Loss: 2.2432\n",
      "time : 10.334776878356934\n",
      "Epoch [70/2000], Loss: 0.9324\n",
      "time : 12.010801076889038\n",
      "Epoch [80/2000], Loss: 0.2726\n",
      "time : 13.698288202285767\n",
      "Epoch [90/2000], Loss: 0.5902\n",
      "time : 15.409220695495605\n",
      "Epoch [100/2000], Loss: 0.4112\n",
      "time : 17.10320019721985\n",
      "training complete\n",
      "Data/Training\\190722_tension_test_space_4_trial_2.csv\n",
      "Epoch [10/2000], Loss: 0.3968\n",
      "time : 2.835381507873535\n",
      "Epoch [20/2000], Loss: 0.6168\n",
      "time : 5.634893417358398\n",
      "Epoch [30/2000], Loss: 0.2467\n",
      "time : 8.461332321166992\n",
      "Epoch [40/2000], Loss: 0.6870\n",
      "time : 11.498716831207275\n",
      "Epoch [50/2000], Loss: 0.3458\n",
      "time : 14.496697425842285\n",
      "Epoch [60/2000], Loss: 0.7393\n",
      "time : 17.443323373794556\n",
      "Epoch [70/2000], Loss: 0.2180\n",
      "time : 20.327117919921875\n",
      "Epoch [80/2000], Loss: 0.2613\n",
      "time : 23.173012256622314\n",
      "Epoch [90/2000], Loss: 0.3895\n",
      "time : 26.012434720993042\n",
      "Epoch [100/2000], Loss: 0.9521\n",
      "time : 28.879273891448975\n",
      "training complete\n",
      "Data/Training\\190722_tension_test_space_4_trial_3.csv\n",
      "Epoch [10/2000], Loss: 0.5345\n",
      "time : 3.569783926010132\n",
      "Epoch [20/2000], Loss: 0.6014\n",
      "time : 7.130765676498413\n",
      "Epoch [30/2000], Loss: 0.0863\n",
      "time : 10.65285348892212\n",
      "Epoch [40/2000], Loss: 3.5979\n",
      "time : 14.208359241485596\n",
      "Epoch [50/2000], Loss: 0.6358\n",
      "time : 17.834171056747437\n",
      "Epoch [60/2000], Loss: 0.2854\n",
      "time : 21.343782663345337\n",
      "Epoch [70/2000], Loss: 0.0363\n",
      "time : 24.83495306968689\n",
      "Epoch [80/2000], Loss: 0.1308\n",
      "time : 28.571977376937866\n",
      "Epoch [90/2000], Loss: 3.1160\n",
      "time : 32.25964403152466\n",
      "Epoch [100/2000], Loss: 0.3458\n",
      "time : 35.936824321746826\n",
      "training complete\n",
      "Data/Training\\190722_tension_test_space_5_trial_2.csv\n",
      "Epoch [10/2000], Loss: 0.1570\n",
      "time : 1.5528466701507568\n",
      "Epoch [20/2000], Loss: 0.1410\n",
      "time : 3.030893564224243\n",
      "Epoch [30/2000], Loss: 0.2141\n",
      "time : 4.489989995956421\n",
      "Epoch [40/2000], Loss: 0.2109\n",
      "time : 5.929139852523804\n",
      "Epoch [50/2000], Loss: 0.2565\n",
      "time : 7.408183813095093\n",
      "Epoch [60/2000], Loss: 0.1752\n",
      "time : 8.857308149337769\n",
      "Epoch [70/2000], Loss: 0.2612\n",
      "time : 10.26006293296814\n",
      "Epoch [80/2000], Loss: 0.3161\n",
      "time : 11.801939010620117\n",
      "Epoch [90/2000], Loss: 0.1810\n",
      "time : 13.290955305099487\n",
      "Epoch [100/2000], Loss: 0.1298\n",
      "time : 14.71414828300476\n",
      "training complete\n",
      "Data/Training\\190722_tension_test_space_5_trial_3.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/2000], Loss: 0.5877\n",
      "time : 5.419503688812256\n",
      "Epoch [20/2000], Loss: 0.1502\n",
      "time : 10.835540056228638\n",
      "Epoch [30/2000], Loss: 0.3031\n",
      "time : 16.230143070220947\n",
      "Epoch [40/2000], Loss: 0.1629\n",
      "time : 21.64465880393982\n",
      "Epoch [50/2000], Loss: 0.1743\n",
      "time : 27.028257369995117\n",
      "Epoch [60/2000], Loss: 0.1178\n",
      "time : 32.40688610076904\n",
      "Epoch [70/2000], Loss: 0.2076\n",
      "time : 37.777551889419556\n",
      "Epoch [80/2000], Loss: 0.1637\n",
      "time : 43.09133744239807\n",
      "Epoch [90/2000], Loss: 0.2175\n",
      "time : 48.43105435371399\n",
      "Epoch [100/2000], Loss: 0.4858\n",
      "time : 53.7667977809906\n",
      "training complete\n",
      "Data/Training\\test11thick_1.csv\n",
      "Epoch [10/2000], Loss: 0.8100\n",
      "time : 1.861527681350708\n",
      "Epoch [20/2000], Loss: 1.0716\n",
      "time : 3.6976571083068848\n",
      "Epoch [30/2000], Loss: 0.5253\n",
      "time : 5.5292649269104\n",
      "Epoch [40/2000], Loss: 1.5593\n",
      "time : 7.345406770706177\n",
      "Epoch [50/2000], Loss: 0.6014\n",
      "time : 9.162546157836914\n",
      "Epoch [60/2000], Loss: 0.9765\n",
      "time : 10.953264236450195\n",
      "Epoch [70/2000], Loss: 0.3933\n",
      "time : 12.803316354751587\n",
      "Epoch [80/2000], Loss: 1.0177\n",
      "time : 14.585548639297485\n",
      "Epoch [90/2000], Loss: 0.7402\n",
      "time : 16.408671140670776\n",
      "Epoch [100/2000], Loss: 0.4718\n",
      "time : 18.190903902053833\n",
      "training complete\n",
      "Data/Training\\test11thick_3.csv\n",
      "Epoch [10/2000], Loss: 0.4528\n",
      "time : 0.5126292705535889\n",
      "Epoch [20/2000], Loss: 0.4882\n",
      "time : 0.9833693504333496\n",
      "Epoch [30/2000], Loss: 0.2082\n",
      "time : 1.439150094985962\n",
      "Epoch [40/2000], Loss: 0.2097\n",
      "time : 1.9258487224578857\n",
      "Epoch [50/2000], Loss: 3.9206\n",
      "time : 2.3896079063415527\n",
      "Epoch [60/2000], Loss: 0.7748\n",
      "time : 2.855362892150879\n",
      "Epoch [70/2000], Loss: 0.0170\n",
      "time : 3.3261032104492188\n",
      "Epoch [80/2000], Loss: 0.5606\n",
      "time : 3.7908599376678467\n",
      "Epoch [90/2000], Loss: 0.0611\n",
      "time : 4.2576117515563965\n",
      "Epoch [100/2000], Loss: 1.8271\n",
      "time : 4.725359916687012\n",
      "training complete\n",
      "Data/Training\\test22thick_2.csv\n",
      "Epoch [10/2000], Loss: 0.3809\n",
      "time : 1.8420724868774414\n",
      "Epoch [20/2000], Loss: 0.7840\n",
      "time : 3.6332807540893555\n",
      "Epoch [30/2000], Loss: 0.4981\n",
      "time : 5.459904909133911\n",
      "Epoch [40/2000], Loss: 1.3512\n",
      "time : 7.269572973251343\n",
      "Epoch [50/2000], Loss: 0.7605\n",
      "time : 9.071751594543457\n",
      "Epoch [60/2000], Loss: 0.2906\n",
      "time : 10.900858879089355\n",
      "Epoch [70/2000], Loss: 0.1201\n",
      "time : 12.705540180206299\n",
      "Epoch [80/2000], Loss: 0.8495\n",
      "time : 14.523676872253418\n",
      "Epoch [90/2000], Loss: 0.6247\n",
      "time : 16.333849668502808\n",
      "Epoch [100/2000], Loss: 0.0583\n",
      "time : 18.128049612045288\n",
      "training complete\n",
      "Data/Training\\test33thick_2.csv\n",
      "Epoch [10/2000], Loss: 0.6625\n",
      "time : 0.716083288192749\n",
      "Epoch [20/2000], Loss: 0.4513\n",
      "time : 1.3823020458221436\n",
      "Epoch [30/2000], Loss: 0.3954\n",
      "time : 2.0624828338623047\n",
      "Epoch [40/2000], Loss: 0.3890\n",
      "time : 2.741666078567505\n",
      "Epoch [50/2000], Loss: 0.5946\n",
      "time : 3.407395601272583\n",
      "Epoch [60/2000], Loss: 0.6015\n",
      "time : 4.093559980392456\n",
      "Epoch [70/2000], Loss: 0.5976\n",
      "time : 4.753794431686401\n",
      "Epoch [80/2000], Loss: 0.5430\n",
      "time : 5.423004150390625\n",
      "Epoch [90/2000], Loss: 0.2045\n",
      "time : 6.102696657180786\n",
      "Epoch [100/2000], Loss: 0.4248\n",
      "time : 6.771905899047852\n",
      "training complete\n",
      "Data/Training\\test33thick_3.csv\n",
      "Epoch [10/2000], Loss: 0.0920\n",
      "time : 1.1050431728363037\n",
      "Epoch [20/2000], Loss: 0.5002\n",
      "time : 2.142268180847168\n",
      "Epoch [30/2000], Loss: 0.1303\n",
      "time : 3.190464973449707\n",
      "Epoch [40/2000], Loss: 0.7242\n",
      "time : 4.23965859413147\n",
      "Epoch [50/2000], Loss: 0.1847\n",
      "time : 5.3048095703125\n",
      "Epoch [60/2000], Loss: 0.3483\n",
      "time : 6.344029664993286\n",
      "Epoch [70/2000], Loss: 0.7399\n",
      "time : 7.384246110916138\n",
      "Epoch [80/2000], Loss: 0.2208\n",
      "time : 8.429450035095215\n",
      "Epoch [90/2000], Loss: 0.2474\n",
      "time : 9.466187238693237\n",
      "Epoch [100/2000], Loss: 0.2252\n",
      "time : 10.519370079040527\n",
      "training complete\n",
      "Data/Training\\test55thick_2.csv\n",
      "Epoch [10/2000], Loss: 1.3323\n",
      "time : 1.1658780574798584\n",
      "Epoch [20/2000], Loss: 0.0529\n",
      "time : 2.2878775596618652\n",
      "Epoch [30/2000], Loss: 1.2582\n",
      "time : 3.432814359664917\n",
      "Epoch [40/2000], Loss: 0.1284\n",
      "time : 4.5906548500061035\n",
      "Epoch [50/2000], Loss: 0.5758\n",
      "time : 5.744566440582275\n",
      "Epoch [60/2000], Loss: 0.5291\n",
      "time : 6.889504671096802\n",
      "Epoch [70/2000], Loss: 1.3919\n",
      "time : 8.018483400344849\n",
      "Epoch [80/2000], Loss: 1.0581\n",
      "time : 9.176385879516602\n",
      "Epoch [90/2000], Loss: 2.4799\n",
      "time : 10.337280988693237\n",
      "Epoch [100/2000], Loss: 2.9112\n",
      "time : 11.472245693206787\n",
      "training complete\n",
      "Data/Training\\test55thick_3.csv\n",
      "Epoch [10/2000], Loss: 0.3245\n",
      "time : 1.5069677829742432\n",
      "Epoch [20/2000], Loss: 0.6176\n",
      "time : 2.9381542205810547\n",
      "Epoch [30/2000], Loss: 0.4798\n",
      "time : 4.370324373245239\n",
      "Epoch [40/2000], Loss: 0.6289\n",
      "time : 5.794513463973999\n",
      "Epoch [50/2000], Loss: 0.3622\n",
      "time : 7.243146657943726\n",
      "Epoch [60/2000], Loss: 0.2991\n",
      "time : 8.70723009109497\n",
      "Epoch [70/2000], Loss: 0.1496\n",
      "time : 10.13441252708435\n",
      "Epoch [80/2000], Loss: 0.6197\n",
      "time : 11.560598134994507\n",
      "Epoch [90/2000], Loss: 0.1356\n",
      "time : 12.981797218322754\n",
      "Epoch [100/2000], Loss: 0.3384\n",
      "time : 14.392024517059326\n",
      "training complete\n"
     ]
    }
   ],
   "source": [
    "for path_idx in os.listdir(data_path_train):\n",
    "    cur_path = os.path.join(data_path_train, path_idx)\n",
    "    print(cur_path)\n",
    "    input_file = np.loadtxt(cur_path, dtype='float', delimiter=',')\n",
    "    # cell = nn.RNN(input_size=4, hidden_size=2, batchfirst=True)\n",
    "    inputs = torch.Tensor(input_file)\n",
    "#     print(inputs[0])\n",
    "    \n",
    "    inputs = inputs[:len(inputs)-len(inputs)%40]\n",
    "#     labels = inputs[:, [5]]\n",
    "# #     print(labels.shape)\n",
    "#     labels = labels.view([-1, 40, 1])\n",
    "    \n",
    "    inputs = inputs[:, [1,2,3,4,6,7,8,9,5]]\n",
    "    inputs = inputs.view([-1,40,9])\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(dataset=inputs,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "    # Train the model\n",
    "    start = time.time()\n",
    "    # for epoch in range(num_epochs):\n",
    "    for epoch in range(100):    \n",
    "        for i, inputs in enumerate(train_loader):\n",
    "            inputs, labels = torch.split(inputs, [8, 1], 2)\n",
    "#             print(\"inputs shape : \", inputs.shape)\n",
    "            inputs = inputs.to(device)\n",
    "    #         labels = labels[:,[39],:].view([-1,1])\n",
    "    #         labels = labels[-1,:,:].view([-1,1])\n",
    "            labels = labels.to(device)\n",
    "    #         print(\"labels shape : \", labels.shape)\n",
    "\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = lstm(inputs)\n",
    "\n",
    "    #         print(labels.shape)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print ('Epoch [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, loss.item()))\n",
    "            print('time :', time.time() - start)\n",
    "    print(\"training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data/Training\\190722_tension_test_space_1_trial_2.csv\n",
      "This is Expectation size 14040\n",
      "Test Accuracy of the model RMSE: 2.2575374285401213\n",
      "Test Accuracy of the model MAE: 1.385511378384994\n",
      "time : 0.26429200172424316\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "Expectation = []\n",
    "Truth = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for path_idx in os.listdir(data_path_train):\n",
    "        cur_path = os.path.join(data_path_train, path_idx)\n",
    "        print(cur_path)\n",
    "        input_file = np.loadtxt(cur_path, dtype='float', delimiter=',')\n",
    "        # cell = nn.RNN(input_size=4, hidden_size=2, batchfirst=True)\n",
    "               \n",
    "        inputs = torch.Tensor(input_file)\n",
    "        inputs = inputs[:len(inputs)-len(inputs)%40]\n",
    "        inputs = inputs[:, [1,2,3,4,6,7,8,9,5]]\n",
    "        inputs = inputs.view([-1,40,9])\n",
    "        \n",
    "        test_loader = torch.utils.data.DataLoader(dataset=inputs,\n",
    "                                       batch_size=batch_size, \n",
    "                                       shuffle=False)\n",
    "        \n",
    "        for inputs in test_loader:\n",
    "\n",
    "            inputs, labels = torch.split(inputs, [8,1], 2)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels[:, : ,:].view([-1,1])\n",
    "            outputs = lstm(inputs)\n",
    "            outputs = outputs[:,:,:].view([-1,1])\n",
    "            \n",
    "            labels_list = labels.tolist()\n",
    "            outputs_list = outputs.tolist()\n",
    "            \n",
    "            zip_lists = zip(labels_list, outputs_list)\n",
    "            for labels, outputs in zip_lists:\n",
    "                Truth.append(labels)\n",
    "                Expectation.append(outputs)\n",
    "\n",
    "#             for i in range(inputs.size(1)):\n",
    "#                 outputs = lstm(inputs[:,i,:].view([inputs.size(0),1,8]))\n",
    "#                 total_outputs += outputs.cpu()           \n",
    "            \n",
    "        break\n",
    "\n",
    "    print(\"This is Expectation size\", len(Expectation))\n",
    "    rmse = mean_squared_error(Expectation, Truth, squared = False)\n",
    "    mae = mean_absolute_error(Expectation, Truth)\n",
    "    \n",
    "    print('Test Accuracy of the model RMSE: {}'.format(rmse))\n",
    "    print('Test Accuracy of the model MAE: {}'.format(mae)) \n",
    "    print('time :', time.time() - start)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save complete\n"
     ]
    }
   ],
   "source": [
    "torch.save(lstm.state_dict(), 'model.ckpt_Hochang')\n",
    "print(\"save complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-2d03ee4e1567>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mExpectation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTruth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(Expectation)\n",
    "plt.plot(Truth)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('fig1.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
